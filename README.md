# ğŸ“Š AvaliaÃ§Ã£o N2 â€” AnÃ¡lise Preditiva

**Aluno:** JosÃ© Victor de Farias  
**Disciplina:** AnÃ¡lise Preditiva  

---

## ğŸ“˜ Sobre a Atividade

Esta avaliaÃ§Ã£o Ã© composta por duas partes principais:
- **QuestÃ£o 1**: AnÃ¡lise multidimensional de dados, utilizando o modelo Star Schema com consultas OLAP (`ROLLUP`, `CUBE`, etc.).
- **QuestÃµes 2 e 3**: ImplementaÃ§Ã£o de um ambiente Data Warehouse (PostgreSQL) e carga de dados clÃ­nicos reais (sintÃ©ticos) para anÃ¡lise preditiva de insuficiÃªncia cardÃ­aca.

---

## ğŸ˜ Ambiente de ExecuÃ§Ã£o

O ambiente foi montado utilizando **Docker** com uma instÃ¢ncia do **PostgreSQL** configurada para rodar localmente via `docker-compose`.

### ğŸ”§ Como subir o ambiente:

```bash
docker-compose up -d
```

- Banco: `analise-preditiva`
- Porta: `5433`
- UsuÃ¡rio: `postgres`
- Senha: `admin123`

---

## ğŸ“¦ QuestÃ£o 1 â€” Star Schema e Consultas OLAP (Online Analytical Processing)

Tabelas criadas:
- `Estudante(estudanteID, nome, curso)`
- `Instrutor(instrutorID, curso)`
- `Aula(aulaID, instituicao, cidade, estado)`
- `Aulas_assistidas(estudanteID, instrutorID, aulaID, notas)` â†’ **tabela fato**

As queries analÃ­ticas foram construÃ­das com `ROLLUP`, `CUBE`, `GROUP BY`, `JOIN` e filtros, para responder perguntas como:
- Qual mÃ©dia por curso?
- Alunos com melhor desempenho em Joinville?
- Agrupamentos hierÃ¡rquicos por geografia e cursos?

Scripts disponÃ­veis em `questao-1/`.

---

## ğŸ©º QuestÃµes 2 e 3 â€” DW com Dataset de SaÃºde (ETL)

### ğŸ“ Dataset:
- **Fonte**: [Kaggle - Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/miadul/heart-failure-prediction-synthetic-dataset)
- **Formato**: `.csv`
- **Registros**: +10.000 pacientes
- **Colunas**: 20 atributos clÃ­nicos/demogrÃ¡ficos

### ğŸ§± Tabela `heart_data` criada com os campos:
- age, gender, chest_pain_type, resting_bp, cholesterol, fasting_blood_sugar,
  resting_ecg, max_heart_rate, exercise_induced_angina, oldpeak, slope,
  num_major_vessels, thalassemia, diabetes, smoking_history,
  alcohol_consumption, physical_activity_level, family_history, bmi, heart_failure

### âš™ï¸ Processo ETL:
- EXTRAÃ‡ÃƒO: leitura do `.csv` original com todas as colunas
- TRANSFORMAÃ‡ÃƒO: ajuste de tipos (ex: BOOLEAN, NUMERIC, VARCHAR)
- CARGA: comando `COPY` via `load_heart_data.sql`

Scripts disponÃ­veis em `questao-2-e-3/`.

---

## ğŸ“ Estrutura do RepositÃ³rio

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ copiar_arquivos.sh
â”œâ”€â”€ executar_scripts.sh
â”œâ”€â”€ questao-1/
â”‚   â”œâ”€â”€ star_schema_postgres.sql
â”‚   â”œâ”€â”€ consultas.sql
â”‚   â””â”€â”€ Relatorio-questao-1.pdf
â”œâ”€â”€ questao-2-e-3/
â”‚   â”œâ”€â”€ create_dw.sql
â”‚   â”œâ”€â”€ load_heart_data.sql
â”‚   â”œâ”€â”€ heart_failure_prediction.csv
â”‚   â””â”€â”€ Relatorio-questao-2-e-3.pdf
â”‚
â””â”€â”€ README.md
```
---

## ğŸ§  ObservaÃ§Ãµes Finais

Para facilitar a execuÃ§Ã£o dos scripts SQL, foram criado dois shell scripts.
### copiar_arquivos.sh
### executar_scripts.sh

O script copiar_arquivos.sh Ã© responsÃ¡vel por copiar arquivos do seu repositÃ³rio local para dentro do container Docker onde estÃ¡ rodando o PostgreSQL.

    Arquivos copiados:

    -star_schema_postgres.sql â†’ criaÃ§Ã£o das tabelas da QuestÃ£o 1

    -create_dw.sql â†’ criaÃ§Ã£o da tabela heart_data da QuestÃ£o 2

    -load_heart_data.sql â†’ comando COPY da QuestÃ£o 3

    -heart_failure_prediction.csv â†’ o dataset com mais de 10.000 registros


O script executar_scripts.sh executa todos os scripts SQL diretamente no banco de dados sem entrar no container manualmente.

    Scripts executados:

    star_schema_postgres.sql â†’ cria o Star Schema da QuestÃ£o 1

    create_dw.sql â†’ cria a estrutura da tabela heart_data

    load_heart_data.sql â†’ insere os dados via COPY


Este projeto foi desenvolvido como parte da AvaliaÃ§Ã£o N2 da disciplina de AnÃ¡lise Preditiva.  
Todas as soluÃ§Ãµes foram testadas em ambiente PostgreSQL Dockerizado, com ETL manual validado.  
